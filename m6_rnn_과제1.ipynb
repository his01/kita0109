{"cells":[{"cell_type":"markdown","metadata":{"id":"YCTjuloC5ooa"},"source":["## ※ Q1_0206. IMDB 영화 리뷰 데이터셋을 사용하여 긍부정 이진분류 모델링 및 평가를 수행하세요. 단, embedding 차원은 8"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6586,"status":"ok","timestamp":1707197592988,"user":{"displayName":"oing R","userId":"16847313320938713906"},"user_tz":-540},"id":"zMH5s0CX5pCc","outputId":"1f6e5e29-12b4-485c-9b87-59e92ab3b20f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n","17464789/17464789 [==============================] - 0s 0us/step\n"]}],"source":["from keras.datasets import imdb\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.models import Sequential\n","from keras.layers import Embedding, Flatten, Dense\n","\n","# 데이터셋 로드\n","# num_words=10000은 훈련 데이터에서 가장 자주 나타나는 상위 10,000개의 단어만 사용하겠다는 의미입니다.\n","(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n","\n","# 시퀀스 데이터 패딩\n","x_train = pad_sequences(x_train, maxlen=100)\n","x_test = pad_sequences(x_test, maxlen=100)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":84142,"status":"ok","timestamp":1707201064367,"user":{"displayName":"oing R","userId":"16847313320938713906"},"user_tz":-540},"id":"WN5W4Y8cG5ad","outputId":"c08b00ec-e7a1-4a3c-838c-5f69a900cecb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential_29\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_23 (Embedding)    (None, 100, 8)            80000     \n","                                                                 \n"," flatten_17 (Flatten)        (None, 800)               0         \n","                                                                 \n"," dense_23 (Dense)            (None, 10)                8010      \n","                                                                 \n"," dense_24 (Dense)            (None, 1)                 11        \n","                                                                 \n","=================================================================\n","Total params: 88021 (343.83 KB)\n","Trainable params: 88021 (343.83 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","Epoch 1/20000\n","938/938 [==============================] - 5s 5ms/step - loss: 0.5074 - accuracy: 0.7301 - val_loss: 0.3542 - val_accuracy: 0.8442\n","Epoch 2/20000\n","938/938 [==============================] - 3s 3ms/step - loss: 0.2414 - accuracy: 0.9069 - val_loss: 0.3681 - val_accuracy: 0.8470\n","Epoch 3/20000\n","938/938 [==============================] - 3s 4ms/step - loss: 0.1193 - accuracy: 0.9636 - val_loss: 0.4467 - val_accuracy: 0.8328\n","Epoch 4/20000\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0474 - accuracy: 0.9908 - val_loss: 0.5113 - val_accuracy: 0.8371\n","Epoch 5/20000\n","938/938 [==============================] - 4s 5ms/step - loss: 0.0205 - accuracy: 0.9967 - val_loss: 0.6198 - val_accuracy: 0.8325\n","Epoch 6/20000\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0098 - accuracy: 0.9985 - val_loss: 0.6555 - val_accuracy: 0.8306\n","Epoch 7/20000\n","938/938 [==============================] - 3s 4ms/step - loss: 0.0046 - accuracy: 0.9993 - val_loss: 0.7508 - val_accuracy: 0.8267\n","Epoch 8/20000\n","938/938 [==============================] - 4s 4ms/step - loss: 0.0019 - accuracy: 0.9997 - val_loss: 0.8466 - val_accuracy: 0.8250\n","Epoch 9/20000\n","938/938 [==============================] - 3s 3ms/step - loss: 4.0747e-04 - accuracy: 1.0000 - val_loss: 0.8975 - val_accuracy: 0.8254\n","Epoch 10/20000\n","938/938 [==============================] - 3s 4ms/step - loss: 1.6460e-04 - accuracy: 1.0000 - val_loss: 0.9369 - val_accuracy: 0.8254\n","Epoch 11/20000\n","938/938 [==============================] - 3s 3ms/step - loss: 9.5098e-05 - accuracy: 1.0000 - val_loss: 0.9765 - val_accuracy: 0.8256\n","Epoch 12/20000\n","938/938 [==============================] - 4s 4ms/step - loss: 5.4435e-05 - accuracy: 1.0000 - val_loss: 1.0212 - val_accuracy: 0.8254\n","Epoch 13/20000\n","938/938 [==============================] - 3s 3ms/step - loss: 3.2052e-05 - accuracy: 1.0000 - val_loss: 1.0610 - val_accuracy: 0.8262\n","Epoch 14/20000\n","938/938 [==============================] - 3s 3ms/step - loss: 1.9047e-05 - accuracy: 1.0000 - val_loss: 1.1087 - val_accuracy: 0.8254\n","Epoch 15/20000\n","938/938 [==============================] - 4s 4ms/step - loss: 1.1330e-05 - accuracy: 1.0000 - val_loss: 1.1508 - val_accuracy: 0.8262\n","Epoch 16/20000\n","938/938 [==============================] - 3s 4ms/step - loss: 6.6768e-06 - accuracy: 1.0000 - val_loss: 1.1945 - val_accuracy: 0.8250\n","Epoch 17/20000\n","938/938 [==============================] - 3s 3ms/step - loss: 3.9549e-06 - accuracy: 1.0000 - val_loss: 1.2406 - val_accuracy: 0.8256\n","Epoch 18/20000\n","938/938 [==============================] - 3s 3ms/step - loss: 2.3885e-06 - accuracy: 1.0000 - val_loss: 1.2870 - val_accuracy: 0.8254\n","Epoch 19/20000\n","938/938 [==============================] - 4s 4ms/step - loss: 1.4034e-06 - accuracy: 1.0000 - val_loss: 1.3310 - val_accuracy: 0.8251\n","Epoch 20/20000\n","938/938 [==============================] - 3s 3ms/step - loss: 8.6771e-07 - accuracy: 1.0000 - val_loss: 1.3778 - val_accuracy: 0.8253\n","Epoch 21/20000\n","938/938 [==============================] - 3s 3ms/step - loss: 5.0537e-07 - accuracy: 1.0000 - val_loss: 1.4226 - val_accuracy: 0.8250\n","Epoch 22/20000\n","938/938 [==============================] - 3s 3ms/step - loss: 3.0781e-07 - accuracy: 1.0000 - val_loss: 1.4657 - val_accuracy: 0.8245\n","782/782 [==============================] - 2s 2ms/step - loss: 1.4696 - accuracy: 0.8208\n","\n","Accuracy: 0.8208\n"]}],"source":["# Q1_ 답1\n","\n","from keras.datasets import imdb\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.models import Sequential\n","from keras.layers import Embedding, Flatten, Dense\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n","\n","# 데이터셋 로드\n","(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words = 10000)\n","\n","# 시퀀스 데이터 패딩\n","x_train = pad_sequences(x_train, maxlen = 100)\n","x_test = pad_sequences(x_test, maxlen = 100)\n","\n","# 모델 구축\n","word_size = 10000\n","model = Sequential([\n","    Embedding(word_size, 8, input_length = 100),\n","    Flatten(),\n","    Dense(10, activation = 'relu'),\n","    Dense(1, activation='sigmoid')  # 이진분류는 출력 뉴런 수를 1로 설정\n","])\n","\n","# 모델 요약 출력\n","model.summary()\n","\n","# EarlyStopping 설정\n","Early_Stopping_Callbacks = EarlyStopping(monitor = 'val_accuracy', patience = 20)\n","\n","# 모델 컴파일 및 결과 출력\n","model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n","model.fit(x_train, y_train, epochs = 20000, batch_size = 20, verbose = 1, validation_split = 0.25, callbacks = [Early_Stopping_Callbacks])\n","print('\\nAccuracy: %.4f' % model.evaluate(x_test, y_test)[1])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30123,"status":"ok","timestamp":1707200958317,"user":{"displayName":"oing R","userId":"16847313320938713906"},"user_tz":-540},"id":"HwrY1q8e8usZ","outputId":"cda53cf7-9682-457c-c04e-f2473b14e491"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential_28\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_22 (Embedding)    (None, 100, 8)            80000     \n","                                                                 \n"," flatten_16 (Flatten)        (None, 800)               0         \n","                                                                 \n"," dense_22 (Dense)            (None, 1)                 801       \n","                                                                 \n","=================================================================\n","Total params: 80801 (315.63 KB)\n","Trainable params: 80801 (315.63 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","Epoch 1/10\n","625/625 [==============================] - 3s 3ms/step - loss: 0.5819 - accuracy: 0.7040 - val_loss: 0.4069 - val_accuracy: 0.8320\n","Epoch 2/10\n","625/625 [==============================] - 2s 3ms/step - loss: 0.3203 - accuracy: 0.8705 - val_loss: 0.3352 - val_accuracy: 0.8508\n","Epoch 3/10\n","625/625 [==============================] - 2s 3ms/step - loss: 0.2360 - accuracy: 0.9109 - val_loss: 0.3298 - val_accuracy: 0.8548\n","Epoch 4/10\n","625/625 [==============================] - 3s 5ms/step - loss: 0.1814 - accuracy: 0.9395 - val_loss: 0.3364 - val_accuracy: 0.8530\n","Epoch 5/10\n","625/625 [==============================] - 2s 3ms/step - loss: 0.1380 - accuracy: 0.9596 - val_loss: 0.3551 - val_accuracy: 0.8496\n","Epoch 6/10\n","625/625 [==============================] - 2s 3ms/step - loss: 0.1012 - accuracy: 0.9761 - val_loss: 0.3761 - val_accuracy: 0.8482\n","Epoch 7/10\n","625/625 [==============================] - 2s 3ms/step - loss: 0.0717 - accuracy: 0.9872 - val_loss: 0.4017 - val_accuracy: 0.8408\n","Epoch 8/10\n","625/625 [==============================] - 2s 3ms/step - loss: 0.0489 - accuracy: 0.9945 - val_loss: 0.4295 - val_accuracy: 0.8408\n","Epoch 9/10\n","625/625 [==============================] - 3s 4ms/step - loss: 0.0326 - accuracy: 0.9980 - val_loss: 0.4591 - val_accuracy: 0.8392\n","Epoch 10/10\n","625/625 [==============================] - 2s 4ms/step - loss: 0.0219 - accuracy: 0.9991 - val_loss: 0.4880 - val_accuracy: 0.8382\n","782/782 [==============================] - 1s 2ms/step - loss: 0.4895 - accuracy: 0.8346\n","Test Accuracy: 0.834559977054596\n"]}],"source":["# Q1_ 답2\n","\n","from keras.datasets import imdb\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.models import Sequential\n","from keras.layers import Embedding, Flatten, Dense\n","\n","# 데이터셋 로드\n","# num_words=10000은 훈련 데이터에서 가장 자주 나타나는 상위 10,000개의 단어만 사용하겠다는 의미입니다.\n","(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n","\n","# 시퀀스 데이터 패딩\n","x_train = pad_sequences(x_train, maxlen=100)\n","x_test = pad_sequences(x_test, maxlen=100)\n","\n","\n","model = Sequential()\n","model.add(Embedding(input_dim=10000, output_dim=8, input_length=100))\n","model.add(Flatten())\n","model.add(Dense(units=1, activation='sigmoid'))\n","\n","\n","model.compile(optimizer='adam',\n","              loss='binary_crossentropy',\n","              metrics=['accuracy'])\n","\n","\n","model.summary()\n","\n","\n","model.fit(x_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n","\n","\n","loss, accuracy = model.evaluate(x_test, y_test)\n","print(\"Test Accuracy:\", accuracy)"]},{"cell_type":"markdown","metadata":{"id":"v-PeSX1ZTqbP"},"source":["## ※ Q2_0206. IDMB 영화 리뷰 데이터셋에 대한 감성 분석을 수행하는 SimpleRNN 모델을 구성하고 훈련하는 예제에 EatlyStopping과 ModelCheckpoint 콜백을 추가하여 모델 훈련을 개선하세요."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":88780,"status":"ok","timestamp":1707266967678,"user":{"displayName":"oing R","userId":"16847313320938713906"},"user_tz":-540},"id":"55u1p9E2ArJK","outputId":"1264d8b5-e188-4f96-a3a0-8e6f4d98d94c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","624/625 [============================>.] - ETA: 0s - loss: 0.5224 - accuracy: 0.7282\n","Epoch 1: val_loss improved from inf to 0.44412, saving model to /content/drive/MyDrive/kita_231026/m6_dl/data/model/best_model.h5\n","625/625 [==============================] - 10s 14ms/step - loss: 0.5224 - accuracy: 0.7283 - val_loss: 0.4441 - val_accuracy: 0.8062\n","Epoch 2/20\n"," 11/625 [..............................] - ETA: 7s - loss: 0.3633 - accuracy: 0.8608"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"name":"stdout","output_type":"stream","text":["622/625 [============================>.] - ETA: 0s - loss: 0.3338 - accuracy: 0.8586\n","Epoch 2: val_loss improved from 0.44412 to 0.41945, saving model to /content/drive/MyDrive/kita_231026/m6_dl/data/model/best_model.h5\n","625/625 [==============================] - 9s 14ms/step - loss: 0.3338 - accuracy: 0.8587 - val_loss: 0.4194 - val_accuracy: 0.8180\n","Epoch 3/20\n","625/625 [==============================] - ETA: 0s - loss: 0.2415 - accuracy: 0.9068\n","Epoch 3: val_loss did not improve from 0.41945\n","625/625 [==============================] - 9s 14ms/step - loss: 0.2415 - accuracy: 0.9068 - val_loss: 0.4389 - val_accuracy: 0.8256\n","Epoch 4/20\n","625/625 [==============================] - ETA: 0s - loss: 0.1557 - accuracy: 0.9444\n","Epoch 4: val_loss did not improve from 0.41945\n","625/625 [==============================] - 8s 13ms/step - loss: 0.1557 - accuracy: 0.9444 - val_loss: 0.5108 - val_accuracy: 0.8292\n","Epoch 5/20\n","624/625 [============================>.] - ETA: 0s - loss: 0.0881 - accuracy: 0.9699\n","Epoch 5: val_loss did not improve from 0.41945\n","625/625 [==============================] - 9s 14ms/step - loss: 0.0885 - accuracy: 0.9697 - val_loss: 0.6060 - val_accuracy: 0.8166\n","Epoch 5: early stopping\n","782/782 [==============================] - 3s 3ms/step - loss: 0.6376 - accuracy: 0.8057\n","Test Accuracy: 0.805679976940155\n"]}],"source":["import numpy as np\n","from keras.datasets import imdb\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.models import Sequential\n","from keras.layers import Embedding, SimpleRNN, Dense\n","from keras.callbacks import EarlyStopping, ModelCheckpoint\n","\n","# IMDB 데이터셋 로드\n","(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n","\n","# 데이터 전처리: 시퀀스 패딩\n","max_len = 100\n","x_train = pad_sequences(x_train, maxlen=max_len)\n","x_test = pad_sequences(x_test, maxlen=max_len)\n","\n","# 모델 구성\n","model = Sequential()\n","model.add(Embedding(input_dim=10000, output_dim=32))\n","model.add(SimpleRNN(units=32))\n","model.add(Dense(units=1, activation='sigmoid'))\n","\n","# 모델 컴파일\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# 콜백 정의: EarlyStopping과 ModelCheckpoint\n","filepath = '/content/drive/MyDrive/kita_231026/m6_dl/data/model/best_model.h5'\n","early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1)\n","model_checkpoint = ModelCheckpoint(filepath= filepath, monitor='val_loss', save_best_only=True, verbose=1)\n","\n","\n","# 모델 훈련\n","history = model.fit(x_train, y_train, epochs=20, batch_size=32, validation_split=0.2, callbacks=[early_stopping, model_checkpoint])\n","\n","# 모델 평가\n","loss, accuracy = model.evaluate(x_test, y_test)\n","print(\"Test Accuracy:\", accuracy)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S5kooWx_F6IU"},"outputs":[],"source":["import numpy as np\n","from keras.datasets import imdb\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.models import Sequential\n","from keras.layers import Embedding, SimpleRNN, Dense\n","from keras.callbacks import EarlyStopping, ModelCheckpoint\n","\n","# IMDB 데이터셋 로드\n","(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n","\n","# 데이터 전처리: 시퀀스 패딩\n","max_len = 100\n","x_train = pad_sequences(x_train, maxlen=max_len)\n","x_test = pad_sequences(x_test, maxlen=max_len)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5724,"status":"ok","timestamp":1707267879376,"user":{"displayName":"oing R","userId":"16847313320938713906"},"user_tz":-540},"id":"wOETncYXBufk","outputId":"fcbef725-eec7-47c9-b7d5-c7787a28858e"},"outputs":[{"name":"stdout","output_type":"stream","text":["782/782 [==============================] - 3s 3ms/step - loss: 0.4182 - accuracy: 0.8181\n","Test Loss: 0.4181574881076813\n","Test Accuracy: 0.8180800080299377\n"]}],"source":["# 저장된 모델을 불러와서 평가에 사용하기\n","from tensorflow.keras.models import load_model\n","\n","# 저장된 모델 불러오기\n","model_path = \"/content/drive/MyDrive/kita_231026/m6_dl/data/model/best_model.h5/\"\n","loaded_model = load_model(model_path)\n","\n","# 테스트 데이터로 모델 평가\n","loss, accuracy = loaded_model.evaluate(x_test, y_test)\n","print(f'Test Loss: {loss}')\n","print(f'Test Accuracy: {accuracy}')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3177,"status":"ok","timestamp":1707268338305,"user":{"displayName":"oing R","userId":"16847313320938713906"},"user_tz":-540},"id":"V9H98fz3H1tK","outputId":"b19aef5d-ff6c-4001-9af9-2fd115be1811"},"outputs":[{"name":"stdout","output_type":"stream","text":["782/782 [==============================] - 3s 3ms/step\n","Sample 1: Probability=0.1466, Class=0\n","Sample 2: Probability=0.9553, Class=1\n","Sample 3: Probability=0.8759, Class=1\n","Sample 4: Probability=0.1972, Class=0\n","Sample 5: Probability=0.9520, Class=1\n","Sample 6: Probability=0.2059, Class=0\n","Sample 7: Probability=0.7069, Class=1\n","Sample 8: Probability=0.0366, Class=0\n","Sample 9: Probability=0.5664, Class=1\n","Sample 10: Probability=0.9108, Class=1\n"]}],"source":["# 출력 결과는 이진 분류 문제에서 모델이 각 샘플에 대해 긍정 클래스(예: 리뷰가 긍정적)에 속할 확률\n","from tensorflow.keras.models import load_model\n","\n","# 저장된 모델 불러오기\n","model_path = \"/content/drive/MyDrive/kita_231026/m6_dl/data/model/best_model.h5/\"\n","loaded_model = load_model(model_path)\n","\n","# 새로운 데이터(여기서는 테스트 데이터셋)에 대해 예측 수행\n","predictions = loaded_model.predict(x_test)\n","predicted_classes = (predictions[:10] > 0.5).astype(int)\n","\n","# 확률과 클래스 레이블 함께 출력\n","for i, (prob, label) in enumerate(zip(predictions, predicted_classes)):\n","    print(f\"Sample {i+1}: Probability={prob[0]:.4f}, Class={label[0]}\")"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOUlbSxmuvvgDyO4anH0YaY","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
