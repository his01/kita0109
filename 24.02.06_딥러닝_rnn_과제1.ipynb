{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNL5vAwiWPuTDbZb6657+fu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## ※ Q1_0206. IMDB 영화 리뷰 데이터셋을 사용하여 긍부정 이진분류 모델링 및 평가를 수행하세요. 단, embedding 차원은 8"],"metadata":{"id":"YCTjuloC5ooa"}},{"cell_type":"code","source":["from keras.datasets import imdb\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.models import Sequential\n","from keras.layers import Embedding, Flatten, Dense\n","\n","# 데이터셋 로드\n","# num_words=10000은 훈련 데이터에서 가장 자주 나타나는 상위 10,000개의 단어만 사용하겠다는 의미입니다.\n","(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n","\n","# 시퀀스 데이터 패딩\n","x_train = pad_sequences(x_train, maxlen=100)\n","x_test = pad_sequences(x_test, maxlen=100)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zMH5s0CX5pCc","executionInfo":{"status":"ok","timestamp":1707197592988,"user_tz":-540,"elapsed":6586,"user":{"displayName":"oing R","userId":"16847313320938713906"}},"outputId":"1f6e5e29-12b4-485c-9b87-59e92ab3b20f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n","17464789/17464789 [==============================] - 0s 0us/step\n"]}]},{"cell_type":"code","source":["# Q1_ 답1\n","\n","from keras.datasets import imdb\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.models import Sequential\n","from keras.layers import Embedding, Flatten, Dense\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n","\n","# 데이터셋 로드\n","(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words = 10000)\n","\n","# 시퀀스 데이터 패딩\n","x_train = pad_sequences(x_train, maxlen = 100)\n","x_test = pad_sequences(x_test, maxlen = 100)\n","\n","# 모델 구축\n","word_size = 10000\n","model = Sequential([\n","    Embedding(word_size, 8, input_length = 100),\n","    Flatten(),\n","    Dense(10, activation = 'relu'),\n","    Dense(1, activation='sigmoid')  # 이진분류는 출력 뉴런 수를 1로 설정\n","])\n","\n","# 모델 요약 출력\n","model.summary()\n","\n","# EarlyStopping 설정\n","Early_Stopping_Callbacks = EarlyStopping(monitor = 'val_accuracy', patience = 20)\n","\n","# 모델 컴파일 및 결과 출력\n","model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n","model.fit(x_train, y_train, epochs = 20000, batch_size = 20, verbose = 1, validation_split = 0.25, callbacks = [Early_Stopping_Callbacks])\n","print('\\nAccuracy: %.4f' % model.evaluate(x_test, y_test)[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WN5W4Y8cG5ad","executionInfo":{"status":"ok","timestamp":1707201064367,"user_tz":-540,"elapsed":84142,"user":{"displayName":"oing R","userId":"16847313320938713906"}},"outputId":"c08b00ec-e7a1-4a3c-838c-5f69a900cecb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_29\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_23 (Embedding)    (None, 100, 8)            80000     \n","                                                                 \n"," flatten_17 (Flatten)        (None, 800)               0         \n","                                                                 \n"," dense_23 (Dense)            (None, 10)                8010      \n","                                                                 \n"," dense_24 (Dense)            (None, 1)                 11        \n","                                                                 \n","=================================================================\n","Total params: 88021 (343.83 KB)\n","Trainable params: 88021 (343.83 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","Epoch 1/20000\n","938/938 [==============================] - 5s 5ms/step - loss: 0.5074 - accuracy: 0.7301 - val_loss: 0.3542 - val_accuracy: 0.8442\n","Epoch 2/20000\n","938/938 [==============================] - 3s 3ms/step - loss: 0.2414 - accuracy: 0.9069 - val_loss: 0.3681 - val_accuracy: 0.8470\n","Epoch 3/20000\n","938/938 [==============================] - 3s 4ms/step - loss: 0.1193 - accuracy: 0.9636 - val_loss: 0.4467 - val_accuracy: 0.8328\n","Epoch 4/20000\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0474 - accuracy: 0.9908 - val_loss: 0.5113 - val_accuracy: 0.8371\n","Epoch 5/20000\n","938/938 [==============================] - 4s 5ms/step - loss: 0.0205 - accuracy: 0.9967 - val_loss: 0.6198 - val_accuracy: 0.8325\n","Epoch 6/20000\n","938/938 [==============================] - 3s 3ms/step - loss: 0.0098 - accuracy: 0.9985 - val_loss: 0.6555 - val_accuracy: 0.8306\n","Epoch 7/20000\n","938/938 [==============================] - 3s 4ms/step - loss: 0.0046 - accuracy: 0.9993 - val_loss: 0.7508 - val_accuracy: 0.8267\n","Epoch 8/20000\n","938/938 [==============================] - 4s 4ms/step - loss: 0.0019 - accuracy: 0.9997 - val_loss: 0.8466 - val_accuracy: 0.8250\n","Epoch 9/20000\n","938/938 [==============================] - 3s 3ms/step - loss: 4.0747e-04 - accuracy: 1.0000 - val_loss: 0.8975 - val_accuracy: 0.8254\n","Epoch 10/20000\n","938/938 [==============================] - 3s 4ms/step - loss: 1.6460e-04 - accuracy: 1.0000 - val_loss: 0.9369 - val_accuracy: 0.8254\n","Epoch 11/20000\n","938/938 [==============================] - 3s 3ms/step - loss: 9.5098e-05 - accuracy: 1.0000 - val_loss: 0.9765 - val_accuracy: 0.8256\n","Epoch 12/20000\n","938/938 [==============================] - 4s 4ms/step - loss: 5.4435e-05 - accuracy: 1.0000 - val_loss: 1.0212 - val_accuracy: 0.8254\n","Epoch 13/20000\n","938/938 [==============================] - 3s 3ms/step - loss: 3.2052e-05 - accuracy: 1.0000 - val_loss: 1.0610 - val_accuracy: 0.8262\n","Epoch 14/20000\n","938/938 [==============================] - 3s 3ms/step - loss: 1.9047e-05 - accuracy: 1.0000 - val_loss: 1.1087 - val_accuracy: 0.8254\n","Epoch 15/20000\n","938/938 [==============================] - 4s 4ms/step - loss: 1.1330e-05 - accuracy: 1.0000 - val_loss: 1.1508 - val_accuracy: 0.8262\n","Epoch 16/20000\n","938/938 [==============================] - 3s 4ms/step - loss: 6.6768e-06 - accuracy: 1.0000 - val_loss: 1.1945 - val_accuracy: 0.8250\n","Epoch 17/20000\n","938/938 [==============================] - 3s 3ms/step - loss: 3.9549e-06 - accuracy: 1.0000 - val_loss: 1.2406 - val_accuracy: 0.8256\n","Epoch 18/20000\n","938/938 [==============================] - 3s 3ms/step - loss: 2.3885e-06 - accuracy: 1.0000 - val_loss: 1.2870 - val_accuracy: 0.8254\n","Epoch 19/20000\n","938/938 [==============================] - 4s 4ms/step - loss: 1.4034e-06 - accuracy: 1.0000 - val_loss: 1.3310 - val_accuracy: 0.8251\n","Epoch 20/20000\n","938/938 [==============================] - 3s 3ms/step - loss: 8.6771e-07 - accuracy: 1.0000 - val_loss: 1.3778 - val_accuracy: 0.8253\n","Epoch 21/20000\n","938/938 [==============================] - 3s 3ms/step - loss: 5.0537e-07 - accuracy: 1.0000 - val_loss: 1.4226 - val_accuracy: 0.8250\n","Epoch 22/20000\n","938/938 [==============================] - 3s 3ms/step - loss: 3.0781e-07 - accuracy: 1.0000 - val_loss: 1.4657 - val_accuracy: 0.8245\n","782/782 [==============================] - 2s 2ms/step - loss: 1.4696 - accuracy: 0.8208\n","\n","Accuracy: 0.8208\n"]}]},{"cell_type":"code","source":["# Q1_ 답2\n","\n","from keras.datasets import imdb\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.models import Sequential\n","from keras.layers import Embedding, Flatten, Dense\n","\n","# 데이터셋 로드\n","# num_words=10000은 훈련 데이터에서 가장 자주 나타나는 상위 10,000개의 단어만 사용하겠다는 의미입니다.\n","(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n","\n","# 시퀀스 데이터 패딩\n","x_train = pad_sequences(x_train, maxlen=100)\n","x_test = pad_sequences(x_test, maxlen=100)\n","\n","\n","model = Sequential()\n","model.add(Embedding(input_dim=10000, output_dim=8, input_length=100))\n","model.add(Flatten())\n","model.add(Dense(units=1, activation='sigmoid'))\n","\n","\n","model.compile(optimizer='adam',\n","              loss='binary_crossentropy',\n","              metrics=['accuracy'])\n","\n","\n","model.summary()\n","\n","\n","model.fit(x_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n","\n","\n","loss, accuracy = model.evaluate(x_test, y_test)\n","print(\"Test Accuracy:\", accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HwrY1q8e8usZ","executionInfo":{"status":"ok","timestamp":1707200958317,"user_tz":-540,"elapsed":30123,"user":{"displayName":"oing R","userId":"16847313320938713906"}},"outputId":"cda53cf7-9682-457c-c04e-f2473b14e491"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_28\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_22 (Embedding)    (None, 100, 8)            80000     \n","                                                                 \n"," flatten_16 (Flatten)        (None, 800)               0         \n","                                                                 \n"," dense_22 (Dense)            (None, 1)                 801       \n","                                                                 \n","=================================================================\n","Total params: 80801 (315.63 KB)\n","Trainable params: 80801 (315.63 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","Epoch 1/10\n","625/625 [==============================] - 3s 3ms/step - loss: 0.5819 - accuracy: 0.7040 - val_loss: 0.4069 - val_accuracy: 0.8320\n","Epoch 2/10\n","625/625 [==============================] - 2s 3ms/step - loss: 0.3203 - accuracy: 0.8705 - val_loss: 0.3352 - val_accuracy: 0.8508\n","Epoch 3/10\n","625/625 [==============================] - 2s 3ms/step - loss: 0.2360 - accuracy: 0.9109 - val_loss: 0.3298 - val_accuracy: 0.8548\n","Epoch 4/10\n","625/625 [==============================] - 3s 5ms/step - loss: 0.1814 - accuracy: 0.9395 - val_loss: 0.3364 - val_accuracy: 0.8530\n","Epoch 5/10\n","625/625 [==============================] - 2s 3ms/step - loss: 0.1380 - accuracy: 0.9596 - val_loss: 0.3551 - val_accuracy: 0.8496\n","Epoch 6/10\n","625/625 [==============================] - 2s 3ms/step - loss: 0.1012 - accuracy: 0.9761 - val_loss: 0.3761 - val_accuracy: 0.8482\n","Epoch 7/10\n","625/625 [==============================] - 2s 3ms/step - loss: 0.0717 - accuracy: 0.9872 - val_loss: 0.4017 - val_accuracy: 0.8408\n","Epoch 8/10\n","625/625 [==============================] - 2s 3ms/step - loss: 0.0489 - accuracy: 0.9945 - val_loss: 0.4295 - val_accuracy: 0.8408\n","Epoch 9/10\n","625/625 [==============================] - 3s 4ms/step - loss: 0.0326 - accuracy: 0.9980 - val_loss: 0.4591 - val_accuracy: 0.8392\n","Epoch 10/10\n","625/625 [==============================] - 2s 4ms/step - loss: 0.0219 - accuracy: 0.9991 - val_loss: 0.4880 - val_accuracy: 0.8382\n","782/782 [==============================] - 1s 2ms/step - loss: 0.4895 - accuracy: 0.8346\n","Test Accuracy: 0.834559977054596\n"]}]},{"cell_type":"markdown","source":["## ※ Q2_0206. IDMB 영화 리뷰 데이터셋에 대한 감성 분석을 수행하는 SimpleRNN 모델을 구성하고 훈련하는 예제에 EatlyStopping과 ModelCheckpoint 콜백을 추가하여 모델 훈련을 개선하세요."],"metadata":{"id":"v-PeSX1ZTqbP"}},{"cell_type":"code","source":["import numpy as np\n","from keras.datasets import imdb\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.models import Sequential\n","from keras.layers import Embedding, SimpleRNN, Dense\n","from keras.callbacks import EarlyStopping, ModelCheckpoint\n","\n","# IMDB 데이터셋 로드\n","(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n","\n","# 데이터 전처리: 시퀀스 패딩\n","max_len = 100\n","x_train = pad_sequences(x_train, maxlen=max_len)\n","x_test = pad_sequences(x_test, maxlen=max_len)\n","\n","# 모델 구성\n","model = Sequential()\n","model.add(Embedding(input_dim=10000, output_dim=32))\n","model.add(SimpleRNN(units=32))\n","model.add(Dense(units=1, activation='sigmoid'))\n","\n","# 모델 컴파일\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# 콜백 정의: EarlyStopping과 ModelCheckpoint\n","filepath = '/content/drive/MyDrive/welcome_to_my_hell/m3통계/딥러닝/data/model/best_model.h5'\n","early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1)\n","model_checkpoint = ModelCheckpoint(filepath= filepath, monitor='val_loss', save_best_only=True, verbose=1)\n","\n","\n","# 모델 훈련\n","history = model.fit(x_train, y_train, epochs=20, batch_size=32, validation_split=0.2, callbacks=[early_stopping, model_checkpoint])\n","\n","# 모델 평가\n","loss, accuracy = model.evaluate(x_test, y_test)\n","print(\"Test Accuracy:\", accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3hBp_-F08CJ6","executionInfo":{"status":"ok","timestamp":1707266617178,"user_tz":-540,"elapsed":157575,"user":{"displayName":"oing R","userId":"16847313320938713906"}},"outputId":"2a7cd91d-37c4-45b5-a985-6cd01a3d655b"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n","17464789/17464789 [==============================] - 0s 0us/step\n","Epoch 1/20\n","625/625 [==============================] - ETA: 0s - loss: 0.5229 - accuracy: 0.7265\n","Epoch 1: val_loss improved from inf to 0.40400, saving model to /content/drive/MyDrive/welcome_to_my_hell/m3통계/딥러닝/data/model/best_model.h5\n","625/625 [==============================] - 18s 27ms/step - loss: 0.5229 - accuracy: 0.7265 - val_loss: 0.4040 - val_accuracy: 0.8234\n","Epoch 2/20\n","  7/625 [..............................] - ETA: 13s - loss: 0.2571 - accuracy: 0.8973"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["625/625 [==============================] - ETA: 0s - loss: 0.3035 - accuracy: 0.8773\n","Epoch 2: val_loss improved from 0.40400 to 0.39335, saving model to /content/drive/MyDrive/welcome_to_my_hell/m3통계/딥러닝/data/model/best_model.h5\n","625/625 [==============================] - 17s 27ms/step - loss: 0.3035 - accuracy: 0.8773 - val_loss: 0.3934 - val_accuracy: 0.8276\n","Epoch 3/20\n","624/625 [============================>.] - ETA: 0s - loss: 0.1802 - accuracy: 0.9336\n","Epoch 3: val_loss did not improve from 0.39335\n","625/625 [==============================] - 16s 26ms/step - loss: 0.1802 - accuracy: 0.9337 - val_loss: 0.4766 - val_accuracy: 0.8288\n","Epoch 4/20\n","625/625 [==============================] - ETA: 0s - loss: 0.0798 - accuracy: 0.9727\n","Epoch 4: val_loss did not improve from 0.39335\n","625/625 [==============================] - 16s 25ms/step - loss: 0.0798 - accuracy: 0.9727 - val_loss: 0.5783 - val_accuracy: 0.7946\n","Epoch 5/20\n","625/625 [==============================] - ETA: 0s - loss: 0.0399 - accuracy: 0.9880\n","Epoch 5: val_loss did not improve from 0.39335\n","625/625 [==============================] - 17s 26ms/step - loss: 0.0399 - accuracy: 0.9880 - val_loss: 0.7056 - val_accuracy: 0.8132\n","Epoch 5: early stopping\n","782/782 [==============================] - 5s 6ms/step - loss: 0.6839 - accuracy: 0.8118\n","Test Accuracy: 0.8118000030517578\n"]}]}]}